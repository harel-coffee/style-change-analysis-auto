{"paragraphs": ["Բազմաթիվ  պրոցեսներ գիտության և ճարտարագիտության  մեջ  բնութագրվում  են  փոքրագույն  քառակուսիների  մեթոդով ստացված  մոդելների  օգնությամբ:  Այս  մոտարկման  եղանակը  հնարավորություն  է տալիս  գծային  կամ  պոլինոմիալ  (բազմանդամային)  ռեգրեսիայի  միջոցով  կառուցել համապատասխան  մոտարկող ֆունկցիան: ", "Դիցուք իրարից  տարբեր \\օ, XI, ճշ..., ճո կետերում հայտնի են քփ<) ֆունկցիայի ք(\\օ), ք(*), ...ք(\\ո)  արժեքները:  Անհրաժեշտ  է  կառուցել  ֆունկցիա,  որը  նկարագրում  է  ք(\\) ֆունկցիայի  վարքագիծը:  Պարտադիր չէ,  որ  այն  անցնի  տրված կետերով:  Սակայն,  այն պետք  է  հնարավորինս  ճշգրիտ  նկարագրի  ֆունկցիայի  վարքագիծը:  Հնարավոր  է,  որ ֆունկցիան  դրսևորի  գծային  վարքագիծ  (Նկար  18),  որը  կբնութագրվի  հետևյալ բանաձևով [43]' (Նկար 19): ", "Անվտանգության  բարձր  մակարդակ  պահանջող  ենթակառուցվածքները,  որտեղ ներքին ցանցը մեկուսացված է արտաքին ցանցից (օրինակ ՀՀ ԶՈՒ), չեն կարող օգտվել այն  համակարգերից,  որոնց  ծառայությունները  հասանելի  են  համացանցի  միջոցով (օրինակ՝  Amazon  SNS):  Հետևաբար  գոյություն  ունեցող  համակարգերից  և  ոչ  մեկը  չի կարող  կիրառվել  այսպիսի  մասնավոր  խնդրիների լուծման  համար։  Այդպիսի միջավայրերի  համար  խնդիր  է  առաջանում  իրականացնել  համակարգ,  որը  կարելի  է ներդնել  ներքին  ցանցում՝  ցանցում  գործող  էլեկտրոնային  փոստի  օգտատերերին նամակների մասին ծանուցման ծառայությունների տրամադրման նպատակով։ ", "Առաջին  դեպքում  անորոշ գործակիցներն (a,  է>) որոշելու համար կիրառվում է գծային ռեգրեսիա:  Իսկ  փոքրագույն քառակուսիների  սխալանքը հաշվվում  է հետևյալ բանձևով [43]' «2 = Տ ն ւ № ՜  (a + i   * x,))2  (19) Երկրորդ  դեպքում  անորոշ գործակիցները  (ao,  ai... an)  որոշելու  համար  կիրառվում  է պոլինոմիալ ռեգրեսիա:  Այս  դեպքում փոքրագույն քառակուսիների սխալանքը հաշվվում է հետևյալ բանաձևով [43]՝ R2  = 'ԼՆւ№  ՜  Օօ + a1xi+ ...+ a 1xik))2,  որտեղ i=0,1,...,n  (20) թեստային  լուծումներ  գեներացնող ք^\"1\"Լ  կոմպիլյատորների  նախագծման  բնութագրերի արագ հիմնված մեթոդի մեթոդի Նկար 20  /?7՜Լ  կոմպիլյատորի նախագծման բնութագրերի գնահատման մեթոդի իրականացման թլոկ-սխեման' փոքրագույն քառակուսիների մեթոդի  կիրառմամթ հիշող  սարքերի  համար  թեստային  լուծումներ  գեներացնող  ք^\"1\"Լ  կոմպիլյատորի ընտվում  են  մոտարկման  կետեր: ", "նախագծման  բնութագրերի  իրական  արժեքները: ", "բնորոշող  մոտարկման  ֆունկցիաները'  վտքրագույն  քառակուսիների  մեթոդի կիրառմամբ: ", "մոտարկման  եղանակով  ստացված  տվյալները  համեմատելու  միջոցով:  Եթե գնահատման  սխալը չի  գերազանցում  10  %-ը,  ապա  տվյալ  մուտքային պարամետրին  համապատասխանող  մոտարկման  ֆունկցիան  օգտագործվում  է արագ գնահատման  մեթոդում:  Իսկ  եթե նշված պայմանը չի  բավարարվում,  ապա անհրաժեշտ  է  լավացնել  բանաձևը'  նոր  ինտերպոլացիոն  կետեր  ավելացնելու, պոլինոմիալ բազմանդամի  աստիճանը  փոխելու միջոցով: ", "Մեթոդը  սկզբում  մշակվել  է  ք^\"Ո_  կոմպիլյատորի  տարրերի  քանակի  արագ գնահատման  համար  [44]:  Այնուհետև  այն  կիրառվել  է  ք^\"Ո_  կոմպիլյատորի  հզորության սպառման  արագ  գնահատման  համար [45]:  Քանի  որ կոմպիլյատորների հիերարխիայի  բոլոր  բաղադրիչներն  ունեն  նման  կառուցվածք,  մեթոդն  հետագայում ընդլայնվել է նանոչափական հիշող սարքերի համար թեստային լուծումներ գեներացնող ք^\"Ո_  կոմպիլյատորների  ամբողջ  հիերարխիայի  նախագծման  բնութագրերի  արագ գնահատման  համար  [46],[47]: ", "Ի  տարբերություն  հատվածագծային  ինտերպոլացիայի  կիրառմամբ  հիշող սարքերի համար  թեստային լուծումներ  գեներացնող  ք^\"Ո_  կոմպիլյատորների  նախագծման բնութագրերի  արագ  գնահատման  մեթոդի  այս  մեթոդը  հնարավորություն  է  տալիս նախագծման  բնութագրերը  գնահատել  ինչպես  գծային  այնպես  էլ  պոլինոմիալ վարքագծի  դեպքում  մեկ  մոտարկման  ֆունկցիայի  միջոցով:  Մշակված մեթոդը  լուծում  է նանոչափական  հիշող  սարքերի  համար  թեստային լուծումներ  գեներացնող  ք^\"Ո_ կոմպիլյատորների  նախագծման  բնութագրերի  գնահատման  խնդիրներից  առաջինը: ", "Այն  էապես  նվազեցնում  է  նախագծման  բնութագրերի  իրական  և  կանխատեսվող արժեքների  միջև  շեղումը'  բարելավելով  գնահատման  սխալը  մինչև  10%:  Սակայն, մեթոդի  իրականացման  համար  անհրաժեշտ  է  ավելացնել  ինտերպոլացիոն  կետերի քանակը,  որի  հետևանքով մեթոդի  իրականացման  ժամանակահատվածը  մեծանում  է: ", "Բացի  դրանից  այն  էապես  կախված  է  ՀՆԹՅ-ի  ճարտարապետությունից  և տեխնոլոգիայից:  Այժմ  շատ  արագ  անցում  է  կատարվում  մեկ  տեխնոլոգիայից  մեկ  այլ տեխնոլոգիայի:  Ուստի,  ներկառուցված  հիշողությունների  ՀՆԹՏ-ի  նախագծման բնութագրերի  արագ  գնահատման  մեթոդը  պետք  է  կարճ  ժամանակահատվածում հարմարեցվի  նոր  տեխնոլոգիաներին'  հնարավորություն  ունենալով աշխատել տարբեր տեխնոլոգիական  ճյուղերով:  Այս  փոփոխությունների  հետ  համընթաց  առաջ  շարժվելու համար  մենք  հետազոտել ենք նախագծման  բնութագրերի  արագ գնահատման  մեթոդի հետագա  ավտոմատացման  հնարավորությունները: ", "Վերջերս  Արհեստական  Բանականությունը  (անգլերեն'  Artificial  Intelligence,  ԱԲ)  մեծ կիրառություն  է  ստացել:  Աշխատանքը  հեշտացնելու  նպատակով  այն  փորձում  են կիրառել  տարբեր  բնագավառներում:  Օրինակ,  տնտեսագետներն  օգտագործում  են ապագա  շուկայի  գները,  օթերևութաբանները'  եղանակի  տեսությունը  կանխատեսելու համար  և  այլն:  Մեքենայական  ուսուցումն  ԱԲ  տարածված ճյուղերից  է,  որը  զբաղվում  է ալգորիթմների  նախագծմամբ  և զարգացմամբ,  որոնք  էմպիրիկ  տվյալների  հիման  վրա կարող  են  բարելավել  իրենց  վարքագիծը:  Էմպիրիկ  տփալներն  օրինակներ  են,  որոնք բնութագրում  են  հետազոտվող  փոփոխականների  միջև  փոխհարաբերությունները: ", "Մեքենայական  ուսուցման  գլխավոր  նպատակն  է  ավտոմատ  սովորել  ճանաչել շաբլոնները,  կայացնել  խելացի  որոշումներ  և  հիմնականում  զբաղվում  է  խնդիրների մոդելավորմամբ'  այսինքն  կանխատեսող  մոդելների  ստեղծմամբ  [47]:  Մեքենայական ուսուցման  ալգորիթմները  բաժանվում  են  երկու  խմբի'  վերահսկվող  (անգլերեն' supervised)  և չվերահսկվող (անգլերեն'  unsupervised)  [49]: ", "Վերահսկվող ուսուցման  դեպքում  ունենք  մուտքային  (X)  փոփոխականը,  ելքային  (Y) փոփոխականը  և  ուսուցման  ալգորիթմը,  որն  օգտագործվում  է  ելքային  արժեքը կանխատեսելու համար  [50]: ", "Y = R X ) Գլխավոր նպատակն  է ստանալ մոտարկողֆունկցիա,  որը նոր մուտքային  տվյալների դեպքում ճշգրիտ  կարտապատկերի  ելքային  արժեքը:  Վերահսկվող ուսուցումը  կարելի է նկարագրել Նկար  21-ում ներկայացված հետևյալ մոդելի  օգնությամբ  [50]: ", "Ուսուցման հավաքածու Մեքենայի ուսուցում Ուսուցումն  իրականացվում  է  պիտակավորված  տվյալների  (անգլերեն'  labeled  data) Նկար 21  Վերահսկող ուսուցման  մոդել [50] միջոցով:  \\ (՚>-ը  մուտքային  փոփոխականներն  են,  որոնք  կոչվում  են  նաև  մուտքային առանձնահատկություններ:  y(i,-ին  ելքային  փոփոխականն է  կամ  թիրախային փոփոխականը,  որն  անհրաժեշտ  է կանխատեսել:  (x(i),  y(i))  կոչվում  է ուսուցման  օրինակ, իսկ  ուսուցման  օրինակների  խումբը  (x(i),  y(i)),  որտեղ  i=1,  2,  ...,  m  կոչվում  է  ուսուցման հավաքածու:  Վերահսկվող  ուսուցման  նպատակն  է  տրված  ուսուցման  հավաքածուի համար  հ:  X  ^   Y  ֆունկցիան  ուսուցանել  այնպես,  որ  այն  “ճշգրիտ”  կանխատեսի համապատասխան  Y  ելքային  արժեքը:  հ  ֆունկցիան  կոչվում  է  հիպոթեզ  [50]: ", "Պիտակավորված դիտարկումներից (անգլերեն՝ labeled observations) հետո առանձնացվում  են  ուսուցման  և  թեստավորման  հավաքածուները:  Ուսուցման հավաքածուի  հետազոտությունից  հետո  ընտրվում  է  ուսուցման  եղանակն  ու իրականացվում  է  մեքենայի  ուսուցումը,  որը  հետագայում  ընտրված  ցանկացած հավաքածուի  համար  կուտակված  փորձի  միջոցով  պետք  է  կանխատեսի  ելքային արժեքները:  Միաժամանակ  թեստավորման  հավաքածուի  միջոցով  իրականացվում  է մեթոդի  ճշտության  ստուգում:  Եթե  ճշգրտման  արդյունքում  պարզվում  է,  որ կանխատեսման  մոդելը  սխալ  է  աշխատում,  ապա  համապատասխան  ճշգրտման ինֆորմացիան  տրվում  է  կանխատեսման  մոդելին:  Այսինքն  կուտակված  փորձի  և ճշգրտումների  շնորհիվ իրականացվում  է մեքենայի  ուսուցում: ", "Ուսուցման  եղանակը  կոչվում  է  վերահսկող,  քանի  որ  տվյալների  հավաքածուով ալգորիթմի  ուսուցման  պրոցեսը  կարելի  է դիտարկել որպես  ուսուցիչ,  որը  վերահսկում է ուսուցման  պրոցեսը:  ճշգրիտ  տվյալնների  հիման  վրա  ալգորիթմն  իրականացնում  է կանխատեսում և ճշգրտվում է ուսուցչի  կողմից:  Ալգորիթմը դադարում է,  երբ ուսուցումը հասնում  է իր  արտադրողականության  թույլատրելի  մակարդակին  [51]: ", "Եթե  թիրախային  փոփոխականը,  որը  փորձում  ենք  կանխատեսել շարունակական  է, ապա  ուսուցման  խնդիրը  կոչվում  է  ռեգրեսիոն  խնդիր:  Այս  դեպքում  ելքային  արժեքն իրական  թիվ է,  օրինակ  քաշ,  դրամ  և  այլն:  Եթե  ունենք  փոքր  քանակությամբ  դիսկրետ արժեքներ,  ապա  գործ  ունենք  դասակարգման  խնդրի  հետ:  Դասակարգման  խնդրի դեպքում ելքային արժեքը հանդիսանում է կատեգորիա,  ինչպիսիք են օրինակ  “ կարմիր” կամ  “ կապույտ” ,  “ հիվանդություն”  կամ  “ ոչ հիվանդություն”  [51]: ", "Չվերահսկող  ուսուցման  դեպքում  ունենք  միայն մուտքային  տվյալ, իսկ համապատասխան  ելքային  արժեքն  անհայտ  է:  Այս  ուսուցման  նպատակն  է  բազային կառուցվածքի  մոդելավորումը  կամ  տվյալների  բաշխումը'  տվյալների  մասին  ավել ինֆորմացիա  ստանալու  նպատակով:  Ի  տարբերություն  վերահսկող  ուսուցման  չկան ճիշտ պատասխաններ և չկա ուսուցիչ:  Չվերահսկվող ուսուցման խնդիրները բաժանվում են  երկու խմբերի'  կլաստերավորում  և ասոցացիա  [51]: ", "Կլաստերավորում:  Այս  դեպքում անհարաժեշտ  է բացահայտել մուտքային  տվյալների խմբերը:  Օրինակ  գնման  վարքագիծը հաշվի  առնելով հաճախորդների  խմբերը: ", "Ինչպես  տեսնում  ենք,  հիշողության  հիմնական  սյուներից  և  տողերից  ոչ  մեկը  չի պարունակում  ամբողջովին  զրոյական  արժեք,  և  տողերի  (սյուների)  արժեքները  չեն կրկնվում, որը իր հերթին  ապահովում է  խճողումների վերծանման միանշանակությունը:  Այս ստուգող հավաքածուն ապահովում է խճողումների հետևյալ տարրերի  ստուգումները.  հիշողության  հասցեավորման  խճողման,  ֆիզիկական  և տրամաբանական տողերի և սյուների համապատասխանության, ինչպես նաև ստուգում է  հավասարակշռող  և  պահեստային  տողերի  և  սյուների  դիրքերի  բաշխման ճշտությունը:  Նշված  խճողումների  ցանկացած  անհամապատասխան  նկարագրումը Նկար 2.11.   ASV ԱՀ-ի hիմնական անկյունագծային  ստուգող հավաքածուն scramble.tcl  ֆայլում  բերում  է  մոդելավորման  սխալ  արդյունքի:  Կախված  նուշի ֆիզիկական չափսերից՝ անհրաժեշտություն է առաջանում մեկ նմուշի համար կիրառել մեկից  ավելի  ծրագրավորման  ֆայլեր:  Հաշվարկները  ցույց  տվեցին,  որ  մեկ  նմուշի խճողումների  լիովին  ստուգման  համար,  վատագույն  դեպքում,  բավական  է  ունենալ երեք  ծրագրավորող  հավաքածու:  Հավելված  2-ում  տրված  է  SIV  հոսքի`  իրական հիշողության  նմուշի (NW=64, NB=8, CM=4,  PR=16, PC=32 ) IPP-ի  ֆայլի օրինակը: ", "Նկ. 2․ 6 -ում բերված է տրամաբանական մոդելավորման մեթոդների դասակարգումը ԻՍ-ի  վերլուծության  համար  բերված  մեթոդներից,  ամենահարմար  տարբերակը սինխրոնային մոդելավորման կիրառումն է[48,50]։ ", "Ռեգրեսիան  կարելի է իրականացնել երկու եղանակներով' նորմալ հավասարումներով (անգլերեն'  Normal  Equation)  և  գրանդիենտային  անկումով (անգլերեն'  Gradient Descent)  [53]: ", "Դիտարկենք  պարզ  գծային  ռեգրեսիայի  մոդելը:  Այս  դեպքում  անկախ փոփոխականների  թիվը  մեկն  է  և գոյություն  ունի  գծային  կախվածություն  x  մուտքային Ել y  ելքային  փոփոխականների  միջև (Նկար 23): "], "paragraph_source_docs": [4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 2, 4, 4], "source_docs_file": "Control, Automation and Electrical Engineering.json"}